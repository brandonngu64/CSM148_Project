# Overview

This project utilizes the “DoorDash ETA Prediction” dataset provided on Kaggle. The aim is to analyze the relationship between order fulfillment time and key predictor variables. The dataset contains many features that influence the estimated time for orders to be completed, including the total busy dashers, number of items in an order, and total outstanding orders. Understanding and modeling the relationship between these features and the estimated time to complete an order will help us make better predictions of delivery times. 

# Methodology

We began with data preprocessing, where efforts were made to clean the dataset by replacing infinite values with NaN and imputing these missing values with column means. We also applied a logarithm transformation to the response variable, order fulfillment time, as well as clipping the 99th percentile of each predictor. After this, the dataset was split into a training set (75%) and a testing set (25%) using the train_test_split function. This split allowed us to train the model on one portion of the data and validate its performance on an unseen test portion.

The core prediction model relies on the RandomForestRegressor, an ensemble method that we use to capture the non-linear relationships among multiple predictor variables. We found the best hyperparameters to include 100 estimators, a maximum depth of 15, and parameters for min_samples_split and min_samples_leaf both set to 6. To find this, we used RandomizedSearchCV to test different combinations of parameters through 20 iterations and 5 folds. With 20 iterations and some tuning of the parameter combinations to try, we found the best results with the ones aforementioned.

# Results

After training the RandomForest model on the dataset, we evaluated its performance using Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and R². On the training set, the RMSE was 0.2477, and on the testing set, it was 0.2957. The MAE values were 0.1934 for training and 0.2325 for testing. Back-transformations (using np.expm1) were then applied to these errors to ensure that the predictions were interpretable in their original scale rather than transformed logarithmic scales.  The Mean Absolute Error (MAE) on the original scale was 543.57 for training and 652.59 for testing. These values indicate the average absolute difference between the actual and predicted delivery times, measured in seconds. While a MAE of over 10 minutes may seem worrisome, it is relatively consistent with our anecdotal observations of delivery app predictions—though it would be interesting to investigate this empirically. The Root Mean Square Error (RMSE) was 753.82 for training and 888.59 for testing. The higher RMSE on the testing set compared to the training set suggests that the model struggles more to generalize accurately across unseen data. The R² values were 0.516 for training and 0.321 for testing, indicating that the model was only capable of explaining 51.6% of the variance in the training set and only 32.1% of the variance in the testing set. This suggests that while the model fits the training data well, it struggles marginally to generalize to unseen data, a typical sign of overfitting. 

The model also provided valuable insights into feature importance, which were critical in understanding the delivery time predictions. Key predictors identified included estimated store-to-consumer driving duration, total outstanding orders, and subtotal amount, which emerged as the top three influential features. We also plotted the residuals to assess the model's performance by analyzing the distribution of prediction errors. In this case, the residuals were decently symmetric and centered around zero, indicating that the model captures the data's overall trends well, while also highlighting that there are some areas for further improvement. These insights can help optimize delivery operations by prioritizing factors that significantly impact delivery efficiency.

While the RandomForestRegressor method worked well for this problem, its main limitation lies in its black-box nature, which restricts interpretability.

# Code Instructions

To use our random forest model, download the “ProjectDoordash_Final_Random_Forest” Python notebook file from our GitHub repository. Open the notebook in your preferred Python notebook application, upload the Doordash dataset, and run all. A copy of the data is in the GitHub files for easier access. The code will clean and log transform the data, split it into a training and validation set, and then create the random forest and output performance metrics.
